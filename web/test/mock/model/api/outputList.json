[
  {
    "id": "fake output id 1",
    "description": "The output of Cassandra use the generic implementation with DataFrames, this implementation transform each UpdateMetricOperation to Row type of Spark and identify each row with his schema.",
    "element": {
      "configuration": {
        "connectionHost": "localhost",
        "dateFormat": "yyyy-mm-dd HH:mm",
        "compactStorage": true,
        "analyzer": "english",
        "connectionPort": "9042",
        "keyspace": "Sparta",
        "keyspaceClass": "simpleStrategy",
        "replication_factor": "1",
        "refreshSeconds": "1"
      },
      "type": "Cassandra",
      "name": "in-Cassandra"
    },
    "fragmentType": "output",
    "shortDescription": "The output of Cassandra use the generic implementation with DataFrames, this implementation transform each UpdateMetricOperation to Row type of Spark and identify each row with his schema.",
    "name": "test_output_cassandra"
  },
  {
    "id": "fake output id 2",
    "description": "The output of ElasticSearch use the generic implementation with DataFrames, this implementation transform each UpdateMetricOperation to Row type of Spark and identify each row with his schema.",
    "element": {
      "configuration": {
        "hostname": "localhost",
        "port": "6379",
        "timeStampFieldName": "timestamp"
      },
      "type": "Redis",
      "name": "in-Redis"
    },
    "fragmentType": "output",
    "shortDescription": "The output of ElasticSearch use the generic implementation with DataFrames, this implementation transform each UpdateMetricOperation to Row type of Spark and identify each row with his schema.",
    "name": "test_output_redis"
  },
  {
    "id": "fake output id 3",
    "description": "The output of ElasticSearch use the generic implementation with DataFrames, this implementation transform each UpdateMetricOperation to Row type of Spark and identify each row with his schema.",
    "element": {
      "configuration": {
        "nodes": [{"node":"localhost","defaultPort":"9300"}],
        "indexMapping": "sparta",
        "idField": ""
      },
      "type": "ElasticSearch",
      "name": "in-ElasticSearch"
    },
    "fragmentType": "output",
    "shortDescription": "The output of ElasticSearch use the generic implementation with DataFrames, this implementation transform each UpdateMetricOperation to Row type of Spark and identify each row with his schema.",
    "name": "test_output_elasticsearch"
  },
  {
    "id": "fake output id 4",
    "description": "MongoDB is an open-source document database that provides high performance, high availability, and automatic scaling.",
    "element": {
      "configuration": {
        "threadsAllowedToBlock": "10",
        "connectionsPerHost": "5",
        "language": "",
        "retrySleep": "1000",
        "hosts": [{"hostName":"localhost","port":"27017"}],
        "idAsField": true,
        "dbName": "sparta"
      },
      "type": "MongoDb",
      "name": "in-MongoDb"
    },
    "fragmentType": "output",
    "shortDescription": "MongoDB is an open-source document database, and the leading NoSQL database.",
    "name": "test_output_mongodb"
  },
  {
    "id": "fake output id 5",
    "description": "Parquet's output uses the generic implementation with DataFrames, this implementation transform each UpdateMetricOperation to Row type of Spark and identify each row with his schema.",
    "element": {
      "configuration": {
        "Path": "dadada"
      },
      "type": "Parquet",
      "name": "in-Parquet"
    },
    "fragmentType": "output",
    "shortDescription": "Parquet's output uses the generic implementation with DataFrames, this implementation transform each UpdateMetricOperation to Row type of Spark and identify each row with his schema.",
    "name": "test_output_parquet"
  },
  {
    "id": "fake output id 6",
    "description": "",
    "element": {
      "configuration": {
        "path": "path_to_csv.csv",
        "delimiter": ",",
        "header": true
      },
      "type": "Csv",
      "name": "in-Csv"
    },
    "fragmentType": "output",
    "shortDescription": "",
    "name": "test_output_csv"
  },
  {
    "id": "fake output id 7",
    "description": "Print's output uses the generic implementation with DataFrames, this implementation transform each UpdateMetricOperation to Row type of Spark and identify each row with his schema.",
    "element": {
      "configuration": {},
      "type": "Print",
      "name": "in-Print"
    },
    "fragmentType": "output",
    "shortDescription": "Print's output uses the generic implementation with DataFrames, this implementation print each dataframe with his schema.",
    "name": "test_output_print"
  }
]
